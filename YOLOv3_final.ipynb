{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyUannnVToZ0p/CRofYr+5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimMinoo/Capstone-Design/blob/main/YOLOv3_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train_YOLOv3 학습"
      ],
      "metadata": {
        "id": "2BNUXJ07DYqu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgPffyuiDS7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66805c2-6ca4-405f-e1f8-96fac07bc0b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "fatal: destination path 'darknet' already exists and is not an empty directory.\n",
            "['/content/darknet/data/obj/1110021.jpg', '/content/darknet/data/obj/1110025.jpg', '/content/darknet/data/obj/1110035.jpg', '/content/darknet/data/obj/1110076.jpg', '/content/darknet/data/obj/1110038.jpg', '/content/darknet/data/obj/1110017.jpg', '/content/darknet/data/obj/1110066.jpg', '/content/darknet/data/obj/1110027.jpg', '/content/darknet/data/obj/1110051.jpg', '/content/darknet/data/obj/1110033.jpg', '/content/darknet/data/obj/1110055.jpg', '/content/darknet/data/obj/1110059.jpg', '/content/darknet/data/obj/1110014.jpg', '/content/darknet/data/obj/1110020.jpg', '/content/darknet/data/obj/1110074.jpg', '/content/darknet/data/obj/1110036.jpg', '/content/darknet/data/obj/1110047.jpg', '/content/darknet/data/obj/1110041.jpg', '/content/darknet/data/obj/1110070.jpg', '/content/darknet/data/obj/1110029.jpg', '/content/darknet/data/obj/1110065.jpg', '/content/darknet/data/obj/1110049.jpg', '/content/darknet/data/obj/1110031.jpg', '/content/darknet/data/obj/1110024.jpg', '/content/darknet/data/obj/1110052.jpg', '/content/darknet/data/obj/1110013.jpg', '/content/darknet/data/obj/1110062.jpg', '/content/darknet/data/obj/1110028.jpg', '/content/darknet/data/obj/1110069.jpg', '/content/darknet/data/obj/1110018.jpg', '/content/darknet/data/obj/1110060.jpg', '/content/darknet/data/obj/1110019.jpg', '/content/darknet/data/obj/1110044.jpg', '/content/darknet/data/obj/1110048.jpg', '/content/darknet/data/obj/1110067.jpg', '/content/darknet/data/obj/1110032.jpg', '/content/darknet/data/obj/1110050.jpg', '/content/darknet/data/obj/1110054.jpg', '/content/darknet/data/obj/1110030.jpg', '/content/darknet/data/obj/1110072.jpg', '/content/darknet/data/obj/1110045.jpg', '/content/darknet/data/obj/1110064.jpg', '/content/darknet/data/obj/1110043.jpg', '/content/darknet/data/obj/1110042.jpg', '/content/darknet/data/obj/1110039.jpg', '/content/darknet/data/obj/1110063.jpg', '/content/darknet/data/obj/1110040.jpg', '/content/darknet/data/obj/1110073.jpg', '/content/darknet/data/obj/1110037.jpg', '/content/darknet/data/obj/1110061.jpg', '/content/darknet/data/obj/1110053.jpg', '/content/darknet/data/obj/1110012.jpg', '/content/darknet/data/obj/1110026.jpg', '/content/darknet/data/obj/1110071.jpg', '/content/darknet/data/obj/1110058.jpg', '/content/darknet/data/obj/1110022.jpg', '/content/darknet/data/obj/1110056.jpg', '/content/darknet/data/obj/1110015.jpg', '/content/darknet/data/obj/1110075.jpg', '/content/darknet/data/obj/1110016.jpg']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/AlexeyAB/darknet\n",
        "\n",
        "# change makefile to have GPU and OPENCV enabled\n",
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!make \n",
        "\n",
        "#!cp cfg/yolov3.cfg cfg/yolov3_training.cfg\n",
        "!cp /content/gdrive/MyDrive/yolov3/data/yolov3_testing.cfg /content/darknet/cfg/yolov3_training.cfg\n",
        "\n",
        "# Download weights darknet model 53\n",
        "!wget https://pjreddie.com/media/files/darknet53.conv.74\n",
        "\n",
        "!echo -e '' > data/obj.names\n",
        "!echo -e '' > data/obj.data\n",
        "!cp /content/drive/MyDrive/yolov3/data/obj.names /content/darknet/data/obj.names\n",
        "!cp /content/drive/MyDrive/yolov3/data/obj.data /content/darknet/data/obj.data\n",
        "!mkdir data/obj\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "src_dir = '/content/drive/MyDrive/yolov3/train_images'\n",
        "dst_dir = '/content/darknet/data/obj'\n",
        "\n",
        "# 디렉토리 내의 모든 파일을 이동합니다.\n",
        "for filename in os.listdir(src_dir):\n",
        "    # 파일 또는 디렉토리의 전체 경로를 구합니다.\n",
        "    src = os.path.join(src_dir, filename)\n",
        "    dst = os.path.join(dst_dir, filename)\n",
        "    # 파일 또는 디렉토리를 이동합니다.\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "import glob\n",
        "images_list = glob.glob(\"/content/darknet/data/obj/*.jpg\")\n",
        "# images_list = glob.glob(\"data/obj/*.png\")\n",
        "print(images_list)\n",
        "\n",
        "#Create training.txt file\n",
        "train = int((len(images_list) / 10) * 8)\n",
        "file = open(\"/content/darknet/data/train.txt\", \"w\") \n",
        "file.write(\"\\n\".join(images_list[:train])) \n",
        "file.close() \n",
        "\n",
        "file = open(\"/content/darknet/data/test.txt\", \"w\") \n",
        "file.write(\"\\n\".join(images_list[train:])) \n",
        "file.close() \n",
        "\n",
        "# Start the training \n",
        "!./darknet detector train data/obj.data cfg/yolov3_training.cfg darknet53.conv.74 -dont_show "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detection_YOLOv3 탐지"
      ],
      "metadata": {
        "id": "Cd3IA6D8EftL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "#OpenCV는 이미지 및 비디오 처리, 객체 감지, 추적, 광학 문자 인식 등의 컴퓨터 비전\n",
        "#애플리케이션을 개발할 때 널리 사용되는 오픈소스 라이브러리이다.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "net = cv2.dnn.readNet(\"/content/gdrive/MyDrive/yolov3/yolov3_training_final.weights\", \"/content/gdrive/MyDrive/yolov3/data/yolov3_testing.cfg\")\n",
        "# 다음 코드는 YOLOv3 객체 감지 알고리즘에 필요한 모델 가중치(weights) 파일과 모델 구성(cfg) 파일을\n",
        "# 읽어와서 신경망 모델(net)을 생성하는 코드이다.\n",
        "\n",
        "#'cv2,dnn' 모듈은 딥러닝 모델을 불러오고 실행하는 기능\n",
        "#'readNet()' 함수는 모델 가중치 파일과 모델 구성 파일을 읽어와서 모델을 생성하는 함수\n",
        "\n",
        "classes = []\n",
        "with open(\"/content/gdrive/MyDrive/yolov3/data/obj.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "layer_names = net.getLayerNames()\n",
        "# 'getLayerNames()' 함수는 모델의 모든 레이어의 이름을 반환한다.\n",
        "\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "# 'getUnconnectedOutLayers()' 함수는 출력 레이어의 인덱스를 반환한다.\n",
        "# Yolov3 모델의 경우, 출력 레이어는 세 개의 레이어로 구성된다.\n",
        "\n",
        "\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "# 객체 클래스에 대한 무작위 색상을 생성한다.\n",
        "# 'np.random.uniform()' 함수는 지정된 범위 내에서 균등한 분포의 무작위 값을 생성한다.\n",
        "# 따라서 위 코드는 객체 클래스 수(len(classes))에 맞게 0~255 범위의 무작위 색생을 생성하여 'color' 리스트에 저장한다.\n",
        "\n",
        "\n",
        "img = cv2.imread(\"/content/drive/MyDrive/1110066/1110044.jpg\")\n",
        "# 위 코드는 파일을 읽어와서 이미지 객체(img)로 변환한다.\n",
        "# cv2.imread()' 함수는 이미지 파일을 읽어와서 Numpy 배열 형태로 반환한다.\n",
        "\n",
        "img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
        "# 위 코드는 이미지 크기를 조정하는 함수이다.\n",
        "# 'fx'와 'fy'는 각각 가로와 세로 방향의 스케일 비율이다.\n",
        "# 위 같은 경우에는 0.4배로 축소되어 저장된다.\n",
        "\n",
        "height, width, channels = img.shape\n",
        "\n",
        "# 따라서 위 코드는 \"image1.jpg\" 파일을 읽어와서 크기를 조정하고, 'height', 'width', 'channels'\n",
        "# 변수에 이미지의 높이, 너비, 채널 정보가 저장된다.\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "# 위 함수는 'img' 이미지를 모델에 입력 가능한 형태인 blob 형태로 변환한다.\n",
        "# 입력 이미지를 전처리하여 CNN 모델의 입력으로 사용할 수 있는 형태로 반환한다.\n",
        "# 이때 인자로 들어가는 '0.00392'는 픽셀값의 스케일링을 의미한다.\n",
        "# Yolov3는 416x416 크기의 입력 이미지를 사용하므로 (416,416)으로 설정한다.\n",
        "# (0,0,0)은 평균값(mean)을 의미한다.\n",
        "# True 옵션은 이미지 채널을 BGR에서 RGB로 변경하는 것을 의미한다.\n",
        "# crop=false는 이미지를 자르지 않는다는 것을 의미한다.\n",
        "\n",
        "net.setInput(blob)\n",
        "# 위 코드는 blob을 모델의 입력으로 설정한다.\n",
        "\n",
        "outs = net.forward(output_layers)\n",
        "# 입력된 이미지를 모델에 입력하고, 출력 레이어('output_layers')에 대한 결과를 반환한다.\n",
        "# Yolov3 모델은 출력 레이어가 세 개로 구성되어 있기 때문에 리스트 형태로 결과값이 반환된다.\n",
        "\n",
        "# 따라서 위 코드를 실행하면 'img' 이미지를 모델의 입력으로 사용하여 객체 감지를 실행하고,\n",
        "# 'outs' 리스트에 출력 결과가 저장된다. 이후 이 출력 결과를 가시화하여 객체 감지 결과를 확인할 수 있다.\n",
        "\n",
        "class_ids = []\n",
        "confidences = []\n",
        "boxes = []\n",
        "for out in outs:\n",
        "    for detection in out:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "        if confidence > 0.5:\n",
        "            center_x = int(detection[0] * width)\n",
        "            center_y = int(detection[1] * height)\n",
        "            w = int(detection[2] * width)\n",
        "            h = int(detection[3] * height)            \n",
        "            x = int(center_x - w / 2)\n",
        "            y = int(center_y - h / 2)\n",
        "            boxes.append([x, y, w, h])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(class_id)\n",
        "\n",
        "\n",
        "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "# 위 코드는 Non-Maximum Suppression 알고리즘을 사용하여 박스를 필터링하고 겹치는 박스들 중\n",
        "# 가장 확률이 높은 박스만 남기는 역할을 한다.\n",
        "# boxes: 경계 상자들의 좌표값들이 담긴 리스트\n",
        "# confidences: 검출된 경계상자들의 신뢰도 값 리스트\n",
        "# score_threshold: 박스의 신뢰도 값이 이 값보다 작은 박스는 제거한다.\n",
        "# nms_threshold: 겹치는 영역의 IOU 값이 이 값보다 큰 박스들을 제거한다.\n",
        "\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "for i in range(len(boxes)):\n",
        "    if i in indexes:\n",
        "        x, y, w, h = boxes[i]\n",
        "        label = str(classes[class_ids[i]])\n",
        "        color = colors[class_ids[i]]\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "        cv2.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
        "cv2_imshow(img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "#여러개의 이미지를 한 번에 Detecting하기\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# net = cv2.dnn.readNet(\"/content/gdrive/MyDrive/yolov3/yolov3_last_training.weights\", \"/content/gdrive/MyDrive/yolov3/data/yolov3_testing.cfg\")\n",
        "# classes = []\n",
        "# with open(\"/content/drive/MyDrive/yolov3/data/obj.names\", \"r\") as f:\n",
        "#     classes = [line.strip() for line in f.readlines()]\n",
        "# layer_names = net.getLayerNames()\n",
        "# output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "# colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "# import glob\n",
        "# img_list = glob.glob(\"/content/darknet/data/obj/train_image/*.jpg\")\n",
        "# images=[]\n",
        "# height=[]\n",
        "# width=[]\n",
        "# channels=[]\n",
        "# for i in range(len(img_list)):\n",
        "#   img = cv2.imread(str(img_list[i]))\n",
        "#   print(img)\n",
        "#   img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
        "#   h, w, ch = img.shape\n",
        "#   images.append(img)\n",
        "#   height.append(h)\n",
        "#   width.append(w)\n",
        "#   channels.append(ch)\n",
        "\n",
        "# result=[]\n",
        "\n",
        "# for i in range(len(images)):\n",
        "#   blob = cv2.dnn.blobFromImage(images[i], 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "#   net.setInput(blob)\n",
        "#   outs = net.forward(output_layers)\n",
        "#   result.append(outs)\n",
        "\n",
        "# final_class_ids = []\n",
        "# final_confidences = []\n",
        "# final_boxes = []\n",
        "\n",
        "# for i,outs in enumerate(result):\n",
        "#   class_ids = []\n",
        "#   confidences = []\n",
        "#   boxes = []\n",
        "#   for out in outs:\n",
        "#       for detection in out:\n",
        "#           scores = detection[5:]\n",
        "#           class_id = np.argmax(scores)\n",
        "#           confidence = scores[class_id]\n",
        "#           if confidence > 0.5:\n",
        "#               center_x = int(detection[0] * width[i])\n",
        "#               center_y = int(detection[1] * height[i])\n",
        "#               w = int(detection[2] * width[i])\n",
        "#               h = int(detection[3] * height[i])            \n",
        "#               x = int(center_x - w / 2)\n",
        "#               y = int(center_y - h / 2)\n",
        "#               boxes.append([x, y, w, h])\n",
        "#               confidences.append(float(confidence))\n",
        "#               class_ids.append(class_id)\n",
        "  \n",
        "#   final_class_ids.append(class_ids)\n",
        "#   final_confidences.append(confidences)\n",
        "#   final_boxes.append(boxes)\n",
        "\n",
        "# final_indexes=[]\n",
        "\n",
        "# for i in range(len(final_boxes)):\n",
        "#   indexes = cv2.dnn.NMSBoxes(final_boxes[i], final_confidences[i], 0.5, 0.4)\n",
        "#   final_indexes.append(indexes)\n",
        "\n",
        "\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# for j in range(len(final_indexes)):\n",
        "#   font = cv2.FONT_HERSHEY_PLAIN\n",
        "#   indexes = final_indexes[j]\n",
        "#   boxes = final_boxes[j]\n",
        "#   class_ids = final_class_ids[j]\n",
        "#   img = images[j]\n",
        "\n",
        "#   for i in range(len(boxes)):\n",
        "#       if i in indexes:\n",
        "#         x, y, w, h = boxes[i]\n",
        "#         label = str(classes[class_ids[i]])\n",
        "#         color = colors[class_ids[i]]\n",
        "#         cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "#         cv2.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
        "#   cv2_imshow(img)\n",
        "#   cv2.waitKey(0)\n",
        "#   cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "ao0Tfa2AEpM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tesseract를 이용하여 text 추출"
      ],
      "metadata": {
        "id": "rrW9pRqFGPxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "!wget https://github.com/tesseract-ocr/tessdata/raw/main/kor.traineddata -P /usr/share/tesseract-ocr/4.00/tessdata\n",
        "import os\n",
        "os.environ['TESSDATA_PREFIX'] = '/usr/share/tesseract-ocr/4.00/tessdata'\n",
        "\n",
        "import cv2\n",
        "import pytesseract\n",
        "\n",
        "# 이미지 열기\n",
        "img = cv2.imread('/content/gdrive/MyDrive/1110066/1110044.jpg')\n",
        "\n",
        "img = cv2.resize(img, None, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "# 이미지 출력\n",
        "cv2_imshow(img)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# 좌표 지정\n",
        "x1s=[]\n",
        "x2s=[]\n",
        "y1s=[]\n",
        "y2s=[]\n",
        "\n",
        "for i in range(len(boxes)):\n",
        "    if i in indexes:\n",
        "      x1, y1, w, h = boxes[i]\n",
        "      x2 = x1 + w\n",
        "      y2 = y1 + h\n",
        "      x1s.append(x1)\n",
        "      y1s.append(y1)\n",
        "      x2s.append(x2)\n",
        "      y2s.append(y2)\n",
        "\n",
        "# 추출할 영역 자르기\n",
        "crop_imgs=[]\n",
        "for j in range(len(x1s)):\n",
        "  crop_img = img[y1s[j]:y2s[j], x1s[j]:x2s[j]]\n",
        "  crop_imgs.append(crop_img)\n",
        "\n",
        "for m in range(len(crop_imgs)):\n",
        "  cv2_imshow(crop_imgs[m])\n",
        "  cv2.waitKey(0)\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "# 추출할 영역을 그레이스케일로 변환\n",
        "gray_imgs=[]\n",
        "for k in range(len(crop_imgs)):\n",
        "  gray_img = cv2.cvtColor(crop_imgs[k], cv2.COLOR_BGR2GRAY)\n",
        "  gray_imgs.append(gray_img)\n",
        "\n",
        "# 추출할 영역에서 문자 추출\n",
        "texts=[]\n",
        "for t in range(len(crop_imgs)):\n",
        "  text = pytesseract.image_to_string(gray_imgs[t],lang='kor+eng')\n",
        "  texts.append(text)\n",
        "\n",
        "for i in range(len(texts)):\n",
        "  print('추출된 텍스트:', texts[i])\n",
        "\n"
      ],
      "metadata": {
        "id": "JgWXHok8GTz_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}